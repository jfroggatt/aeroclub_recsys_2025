{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RelativeCostFeatureEngineer:\n",
    "    \"\"\"\n",
    "    Engineer relative cost features for flight selection prediction.\n",
    "    Captures price positioning within each search session.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.search_stats = {}\n",
    "\n",
    "    def calculate_search_level_price_features(self, df):\n",
    "        \"\"\"\n",
    "        Calculate relative price features within each search session.\n",
    "        Assumes each unique combination of (profileId, ranker_id, requestDate) represents one search.\n",
    "        \"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "\n",
    "        # Create search session identifier\n",
    "        search_cols = ['profileId', 'ranker_id', 'requestDate']\n",
    "        missing_cols = [col for col in search_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Warning: Missing columns {missing_cols}. Using available columns for search grouping.\")\n",
    "            available_cols = [col for col in search_cols if col in df.columns]\n",
    "            if not available_cols:\n",
    "                print(\"No search session columns found. Using index as search session.\")\n",
    "                df['search_session'] = 0  # Single search session\n",
    "                search_id_col = 'search_session'\n",
    "            else:\n",
    "                search_id_col = available_cols[0] if len(available_cols) == 1 else 'combined_search_id'\n",
    "                if len(available_cols) > 1:\n",
    "                    df[search_id_col] = df[available_cols].astype(str).agg('_'.join, axis=1)\n",
    "        else:\n",
    "            search_id_col = 'search_session_id'\n",
    "            df[search_id_col] = df[search_cols].astype(str).agg('_'.join, axis=1)\n",
    "\n",
    "        # Group by search session and calculate relative metrics\n",
    "        for search_id, group in df.groupby(search_id_col):\n",
    "            group_idx = group.index\n",
    "            prices = group['totalPrice'].values\n",
    "\n",
    "            if len(prices) <= 1:\n",
    "                # Single flight in search - set neutral values\n",
    "                features.loc[group_idx, 'price_rank'] = 1\n",
    "                features.loc[group_idx, 'price_percentile'] = 50.0\n",
    "                features.loc[group_idx, 'price_zscore'] = 0.0\n",
    "                features.loc[group_idx, 'price_ratio_to_min'] = 1.0\n",
    "                features.loc[group_idx, 'price_ratio_to_max'] = 1.0\n",
    "                features.loc[group_idx, 'price_ratio_to_median'] = 1.0\n",
    "                features.loc[group_idx, 'is_cheapest'] = 1\n",
    "                features.loc[group_idx, 'is_most_expensive'] = 1\n",
    "                features.loc[group_idx, 'price_gap_to_next_cheapest'] = 0.0\n",
    "                features.loc[group_idx, 'options_count'] = 1\n",
    "                continue\n",
    "\n",
    "            # Basic ranking features\n",
    "            price_ranks = stats.rankdata(prices, method='min')\n",
    "            features.loc[group_idx, 'price_rank'] = price_ranks\n",
    "\n",
    "            # Percentile within search (0-100, lower = cheaper)\n",
    "            price_percentiles = [(rank - 1) / (len(prices) - 1) * 100 for rank in price_ranks]\n",
    "            features.loc[group_idx, 'price_percentile'] = price_percentiles\n",
    "\n",
    "            # Z-score within search (standardized price position)\n",
    "            if prices.std() > 0:\n",
    "                price_zscores = (prices - prices.mean()) / prices.std()\n",
    "                features.loc[group_idx, 'price_zscore'] = price_zscores\n",
    "            else:\n",
    "                features.loc[group_idx, 'price_zscore'] = 0.0\n",
    "\n",
    "            # Ratio features\n",
    "            min_price = prices.min()\n",
    "            max_price = prices.max()\n",
    "            median_price = np.median(prices)\n",
    "\n",
    "            features.loc[group_idx, 'price_ratio_to_min'] = prices / min_price\n",
    "            features.loc[group_idx, 'price_ratio_to_max'] = prices / max_price\n",
    "            features.loc[group_idx, 'price_ratio_to_median'] = prices / median_price\n",
    "\n",
    "            # Binary position features\n",
    "            features.loc[group_idx, 'is_cheapest'] = (prices == min_price).astype(int)\n",
    "            features.loc[group_idx, 'is_most_expensive'] = (prices == max_price).astype(int)\n",
    "            features.loc[group_idx, 'is_below_median'] = (prices < median_price).astype(int)\n",
    "\n",
    "            # Price gap analysis\n",
    "            sorted_prices = np.sort(prices)\n",
    "            price_gaps = []\n",
    "            for price in prices:\n",
    "                current_rank = np.where(sorted_prices == price)[0][0]\n",
    "                if current_rank < len(sorted_prices) - 1:\n",
    "                    gap = sorted_prices[current_rank + 1] - price\n",
    "                else:\n",
    "                    gap = 0  # Most expensive flight\n",
    "                price_gaps.append(gap)\n",
    "\n",
    "            features.loc[group_idx, 'price_gap_to_next_cheapest'] = price_gaps\n",
    "\n",
    "            # Search context features\n",
    "            features.loc[group_idx, 'options_count'] = len(prices)\n",
    "            features.loc[group_idx, 'price_range'] = max_price - min_price\n",
    "            features.loc[group_idx, 'price_std'] = prices.std()\n",
    "            features.loc[group_idx, 'price_cv'] = prices.std() / prices.mean() if prices.mean() > 0 else 0\n",
    "\n",
    "        return features.fillna(0)\n",
    "\n",
    "    def calculate_price_tiers(self, df, n_tiers=5):\n",
    "        \"\"\"Create price tier features within each search\"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "\n",
    "        # Create search session identifier (same logic as above)\n",
    "        search_cols = ['profileId', 'ranker_id', 'requestDate']\n",
    "        available_cols = [col for col in search_cols if col in df.columns]\n",
    "\n",
    "        if not available_cols:\n",
    "            df['search_session'] = 0\n",
    "            search_id_col = 'search_session'\n",
    "        else:\n",
    "            search_id_col = available_cols[0] if len(available_cols) == 1 else 'combined_search_id'\n",
    "            if len(available_cols) > 1:\n",
    "                df[search_id_col] = df[available_cols].astype(str).agg('_'.join, axis=1)\n",
    "\n",
    "        for search_id, group in df.groupby(search_id_col):\n",
    "            group_idx = group.index\n",
    "            prices = group['totalPrice'].values\n",
    "\n",
    "            if len(prices) <= 1:\n",
    "                features.loc[group_idx, 'price_tier'] = 1\n",
    "                features.loc[group_idx, f'is_tier_1'] = 1\n",
    "                for tier in range(2, n_tiers + 1):\n",
    "                    features.loc[group_idx, f'is_tier_{tier}'] = 0\n",
    "                continue\n",
    "\n",
    "            # Create price tiers using quantiles\n",
    "            if len(set(prices)) >= n_tiers:\n",
    "                # Use quantile-based tiers when we have enough unique prices\n",
    "                tier_boundaries = np.percentile(prices, [i * 100/n_tiers for i in range(n_tiers + 1)])\n",
    "                price_tiers = pd.cut(prices, bins=tier_boundaries, labels=range(1, n_tiers + 1),\n",
    "                                   include_lowest=True, duplicates='drop')\n",
    "            else:\n",
    "                # Use rank-based tiers for limited unique prices\n",
    "                price_ranks = stats.rankdata(prices, method='min')\n",
    "                max_rank = price_ranks.max()\n",
    "                tier_size = max_rank / n_tiers\n",
    "                price_tiers = np.ceil(price_ranks / tier_size).astype(int)\n",
    "                price_tiers = np.clip(price_tiers, 1, n_tiers)\n",
    "\n",
    "            features.loc[group_idx, 'price_tier'] = price_tiers\n",
    "\n",
    "            # Create binary tier features\n",
    "            for tier in range(1, n_tiers + 1):\n",
    "                features.loc[group_idx, f'is_tier_{tier}'] = (price_tiers == tier).astype(int)\n",
    "\n",
    "        return features.fillna(0)\n",
    "\n",
    "    def calculate_value_score(self, df):\n",
    "        \"\"\"\n",
    "        Calculate a value score that considers both price and quality indicators.\n",
    "        Lower prices with better features = higher value score.\n",
    "        \"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "\n",
    "        # Create search session identifier\n",
    "        search_cols = ['profileId', 'ranker_id', 'requestDate']\n",
    "        available_cols = [col for col in search_cols if col in df.columns]\n",
    "\n",
    "        if not available_cols:\n",
    "            df['search_session'] = 0\n",
    "            search_id_col = 'search_session'\n",
    "        else:\n",
    "            search_id_col = available_cols[0] if len(available_cols) == 1 else 'combined_search_id'\n",
    "            if len(available_cols) > 1:\n",
    "                df[search_id_col] = df[available_cols].astype(str).agg('_'.join, axis=1)\n",
    "\n",
    "        for search_id, group in df.groupby(search_id_col):\n",
    "            group_idx = group.index\n",
    "\n",
    "            # Quality indicators (you can customize these based on your data)\n",
    "            quality_features = []\n",
    "\n",
    "            # Duration efficiency (shorter is better)\n",
    "            if 'legs0_duration' in df.columns:\n",
    "                duration_mins = pd.to_timedelta(group['legs0_duration']).dt.total_seconds() / 60\n",
    "                if 'legs1_duration' in df.columns:\n",
    "                    duration_mins += pd.to_timedelta(group['legs1_duration']).dt.total_seconds() / 60\n",
    "\n",
    "                # Normalize duration (lower is better, so invert)\n",
    "                if duration_mins.std() > 0:\n",
    "                    duration_score = 1 - (duration_mins - duration_mins.min()) / (duration_mins.max() - duration_mins.min())\n",
    "                else:\n",
    "                    duration_score = pd.Series([1.0] * len(group), index=group.index)\n",
    "                quality_features.append(duration_score)\n",
    "\n",
    "            # Direct flights preference (fewer segments is better)\n",
    "            total_segments = 0\n",
    "            segment_cols = [col for col in df.columns if 'segments1_' in col and 'aircraft_code' in col]\n",
    "            if segment_cols:\n",
    "                for col in segment_cols:\n",
    "                    total_segments += (~group[col].isna()).astype(int)\n",
    "                total_segments += 2  # Base segments (legs0_segments0 and legs1_segments0)\n",
    "\n",
    "                # Invert so fewer segments = higher score\n",
    "                if total_segments.std() > 0:\n",
    "                    segment_score = 1 - (total_segments - total_segments.min()) / (total_segments.max() - total_segments.min())\n",
    "                else:\n",
    "                    segment_score = pd.Series([1.0] * len(group), index=group.index)\n",
    "                quality_features.append(segment_score)\n",
    "\n",
    "            # Seat availability (more available seats = better)\n",
    "            seat_cols = [col for col in df.columns if 'seatsAvailable' in col]\n",
    "            if seat_cols:\n",
    "                total_seats = group[seat_cols].sum(axis=1)\n",
    "                if total_seats.std() > 0:\n",
    "                    seat_score = (total_seats - total_seats.min()) / (total_seats.max() - total_seats.min())\n",
    "                else:\n",
    "                    seat_score = pd.Series([1.0] * len(group), index=group.index)\n",
    "                quality_features.append(seat_score)\n",
    "\n",
    "            # Baggage allowance (more is better)\n",
    "            baggage_cols = [col for col in df.columns if 'baggageAllowance_quantity' in col]\n",
    "            if baggage_cols:\n",
    "                total_baggage = group[baggage_cols].sum(axis=1)\n",
    "                if total_baggage.std() > 0:\n",
    "                    baggage_score = (total_baggage - total_baggage.min()) / (total_baggage.max() - total_baggage.min())\n",
    "                else:\n",
    "                    baggage_score = pd.Series([1.0] * len(group), index=group.index)\n",
    "                quality_features.append(baggage_score)\n",
    "\n",
    "            # Combine quality features\n",
    "            if quality_features:\n",
    "                quality_score = pd.concat(quality_features, axis=1).mean(axis=1)\n",
    "            else:\n",
    "                quality_score = pd.Series([0.5] * len(group), index=group.index)  # Neutral score\n",
    "\n",
    "            # Price score (lower price = higher score)\n",
    "            prices = group['totalPrice']\n",
    "            if prices.std() > 0:\n",
    "                price_score = 1 - (prices - prices.min()) / (prices.max() - prices.min())\n",
    "            else:\n",
    "                price_score = pd.Series([1.0] * len(group), index=group.index)\n",
    "\n",
    "            # Combined value score (weighted combination)\n",
    "            value_score = (price_score * 0.6 + quality_score * 0.4) * 100\n",
    "            features.loc[group_idx, 'value_score'] = value_score\n",
    "\n",
    "            # Value tier based on value score\n",
    "            if len(group) > 1:\n",
    "                value_tiers = pd.qcut(value_score, q=3, labels=['Low Value', 'Medium Value', 'High Value'],\n",
    "                                    duplicates='drop')\n",
    "                features.loc[group_idx, 'value_tier'] = value_tiers\n",
    "                features.loc[group_idx, 'is_high_value'] = (value_tiers == 'High Value').astype(int)\n",
    "            else:\n",
    "                features.loc[group_idx, 'value_tier'] = 'Medium Value'\n",
    "                features.loc[group_idx, 'is_high_value'] = 0\n",
    "\n",
    "        return features.fillna(0)\n",
    "\n",
    "    def calculate_competitive_price_position(self, df):\n",
    "        \"\"\"Calculate price position relative to market expectations\"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "\n",
    "        # Calculate expected price based on route, duration, etc.\n",
    "        # Group by similar flights to establish price expectations\n",
    "        route_price_stats = df.groupby('searchRoute')['totalPrice'].agg(['mean', 'median', 'std']).reset_index()\n",
    "        route_price_stats.columns = ['searchRoute', 'route_avg_price', 'route_median_price', 'route_price_std']\n",
    "\n",
    "        # Merge back to get expected prices\n",
    "        df_with_expectations = df.merge(route_price_stats, on='searchRoute', how='left')\n",
    "\n",
    "        # Calculate relative position vs. route expectations\n",
    "        features['price_vs_route_avg'] = (df_with_expectations['totalPrice'] /\n",
    "                                        df_with_expectations['route_avg_price'] - 1) * 100\n",
    "\n",
    "        features['price_vs_route_median'] = (df_with_expectations['totalPrice'] /\n",
    "                                           df_with_expectations['route_median_price'] - 1) * 100\n",
    "\n",
    "        # Z-score relative to route historical prices\n",
    "        features['price_zscore_vs_route'] = np.where(\n",
    "            df_with_expectations['route_price_std'] > 0,\n",
    "            (df_with_expectations['totalPrice'] - df_with_expectations['route_avg_price']) /\n",
    "            df_with_expectations['route_price_std'],\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # Price surprise (how different from expected)\n",
    "        features['price_surprise_score'] = np.abs(features['price_vs_route_median'])\n",
    "\n",
    "        # Price attractiveness categories\n",
    "        features['price_category'] = pd.cut(\n",
    "            features['price_vs_route_median'],\n",
    "            bins=[-float('inf'), -20, -10, 10, 20, float('inf')],\n",
    "            labels=['Very Cheap', 'Cheap', 'Fair', 'Expensive', 'Very Expensive']\n",
    "        )\n",
    "\n",
    "        return features.fillna(0)\n",
    "\n",
    "    def generate_all_relative_cost_features(self, df):\n",
    "        \"\"\"Generate comprehensive relative cost features\"\"\"\n",
    "        print(\"Generating relative cost features...\")\n",
    "\n",
    "        # Basic relative price features\n",
    "        search_level_features = self.calculate_search_level_price_features(df)\n",
    "\n",
    "        # Price tier features\n",
    "        tier_features = self.calculate_price_tiers(df, n_tiers=5)\n",
    "\n",
    "        # Value score features\n",
    "        value_features = self.calculate_value_score(df)\n",
    "\n",
    "        # Competitive position features\n",
    "        competitive_features = self.calculate_competitive_price_position(df)\n",
    "\n",
    "        # Combine all features\n",
    "        all_features = pd.concat([\n",
    "            search_level_features,\n",
    "            tier_features,\n",
    "            value_features,\n",
    "            competitive_features\n",
    "        ], axis=1)\n",
    "\n",
    "        print(f\"Generated {len(all_features.columns)} relative cost features\")\n",
    "        return all_features\n",
    "\n",
    "# Example usage and testing\n",
    "def demonstrate_relative_cost_features():\n",
    "    \"\"\"Demonstrate the relative cost feature engineering\"\"\"\n",
    "    print(\"=== RELATIVE COST FEATURE ENGINEERING DEMO ===\\n\")\n",
    "\n",
    "    # Create sample data to demonstrate\n",
    "    np.random.seed(42)\n",
    "    sample_data = {\n",
    "        'profileId': [1, 1, 1, 1, 2, 2, 2],\n",
    "        'ranker_id': ['a', 'a', 'a', 'a', 'b', 'b', 'b'],\n",
    "        'requestDate': pd.to_datetime(['2024-06-01'] * 4 + ['2024-06-02'] * 3),\n",
    "        'totalPrice': [15000, 18000, 22000, 25000, 12000, 16000, 20000],\n",
    "        'searchRoute': ['TLKKJA/KJATLK'] * 7,\n",
    "        'legs0_duration': ['02:40:00'] * 7,\n",
    "        'legs1_duration': ['02:35:00'] * 7\n",
    "    }\n",
    "\n",
    "    sample_df = pd.DataFrame(sample_data)\n",
    "\n",
    "    # Generate features\n",
    "    feature_engineer = RelativeCostFeatureEngineer()\n",
    "    cost_features = feature_engineer.generate_all_relative_cost_features(sample_df)\n",
    "\n",
    "    print(\"Sample relative cost features:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Show key features for first search session\n",
    "    key_features = [\n",
    "        'price_rank', 'price_percentile', 'price_ratio_to_min',\n",
    "        'is_cheapest', 'price_tier', 'value_score'\n",
    "    ]\n",
    "\n",
    "    print(\"Search Session 1 (4 flights):\")\n",
    "    search_1_features = cost_features.iloc[:4][key_features]\n",
    "    search_1_features['totalPrice'] = sample_df.iloc[:4]['totalPrice']\n",
    "    print(search_1_features.round(2))\n",
    "\n",
    "    print(\"\\nSearch Session 2 (3 flights):\")\n",
    "    search_2_features = cost_features.iloc[4:][key_features]\n",
    "    search_2_features['totalPrice'] = sample_df.iloc[4:]['totalPrice']\n",
    "    print(search_2_features.round(2))\n",
    "\n",
    "    print(f\"\\nTotal features generated: {len(cost_features.columns)}\")\n",
    "    print(\"Feature names:\", list(cost_features.columns))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demonstrate_relative_cost_features()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
